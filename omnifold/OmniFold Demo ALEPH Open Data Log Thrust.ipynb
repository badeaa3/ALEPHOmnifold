{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OmniFold with ALEPH Open Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anthonybadea/anaconda3/envs/rpv_multijet/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "import energyflow as ef\n",
    "import energyflow.archs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import uproot\n",
    "\n",
    "import omnifold\n",
    "import modplot\n",
    "import ibu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.figsize'] = (4,4)\n",
    "#plt.rcParams['figure.dpi'] = 120\n",
    "#plt.rcParams['font.family'] = 'serif'\n",
    "#plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aleph_path = '/Users/anthonybadea/Documents/ALEPH/ALEPH'\n",
    "event_selections = [\n",
    "    'passesNTupleAfterCut',\n",
    "    'passesTotalChgEnergyMin', \n",
    "    'passesNTrkMin', \n",
    "    'passesNeuNch',\n",
    "    'passesSTheta'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_years = [\n",
    "    #'1992', \n",
    "    #'1993', \n",
    "    '1994', \n",
    "    #'1995'\n",
    "]\n",
    "\n",
    "# load data by year\n",
    "data = {'yearly_thrust': [], 'yearly_evmask': []}\n",
    "for year in data_years:\n",
    "    data_file = uproot.open(os.path.join(aleph_path, 'LEP1Data{}_recons_aftercut-MERGED.root'.format(year)))\n",
    "    t = data_file['t']\n",
    "    \n",
    "    event_mask = np.ones(t.num_entries, dtype=bool) # len(t['EventNo'])\n",
    "    for evsel in event_selections:\n",
    "        event_mask = np.logical_and(event_mask,t[evsel].array()) #&= t[evsel].array()\n",
    "        \n",
    "    data['yearly_evmask'].append(event_mask)\n",
    "    data['yearly_thrust'].append(1 - t['Thrust'].array())\n",
    "\n",
    "data['evmask'] = np.concatenate(data['yearly_evmask'])\n",
    "data['thrust'] = np.concatenate(data['yearly_thrust'])\n",
    "data['sel_thrust'] = data['thrust'][data['evmask']]\n",
    "data['log_thrust'] = np.log(data['thrust'])\n",
    "data['log_sel_thrust'] = np.log(data['sel_thrust'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mc, currently just get thrust values\n",
    "mc_file = uproot.open(os.path.join(aleph_path, 'alephMCRecoAfterCutPaths_1994.root'))\n",
    "\n",
    "event_mask = np.ones(mc_file['t'].num_entries, dtype=bool)\n",
    "before_masks = []\n",
    "for evsel in event_selections:\n",
    "    event_mask = np.logical_and(event_mask,mc_file['t'][evsel].array()) #&=mc_file['t'][evsel].array()\n",
    "    before_masks.append(mc_file['tgenBefore'][evsel].array())\n",
    "    \n",
    "mc = {\n",
    "    'log_sim_thrust': np.log(1 - mc_file['t']['Thrust'].array()),\n",
    "    'log_gen_thrust': np.log(1 - mc_file['tgen']['Thrust'].array()),\n",
    "    'log_genBefore_thrust': np.log(1 - mc_file['tgenBefore']['Thrust'].array()),\n",
    "}\n",
    "mc['log_sel_sim_thrust'] = mc['log_sim_thrust'][event_mask]\n",
    "mc['log_sel_gen_thrust'] = mc['log_gen_thrust'][event_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these dicts are used by OmniFold\n",
    "nature = {'data_thrust': data['log_sel_thrust']}\n",
    "synthetic = {'sim_thrust': mc['log_sel_sim_thrust'], 'gen_thrust': mc['log_sel_gen_thrust']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute the distributions to determine the bin-by-bin corrections\n",
    "bins = np.linspace(-8, np.log(0.5), 51)\n",
    "density = True\n",
    "\n",
    "opts = {'bins': bins, 'histtype': 'step', 'density': density}\n",
    "\n",
    "plt.hist(data['log_thrust'], color='black', label='Data - 1994', **opts)\n",
    "plt.hist(data['log_sel_thrust'], color='gray', label='Data - 1994 sel.', **opts)\n",
    "\n",
    "plt.hist(mc['log_sim_thrust'], color='orange', label='SIM', **opts)\n",
    "simhist = plt.hist(synthetic['sim_thrust'], color='tab:olive', label='SIM sel.', **opts)[0]\n",
    "\n",
    "plt.hist(mc['log_gen_thrust'], color='blue', label='GEN', **opts)\n",
    "genhist = plt.hist(synthetic['gen_thrust'], color='cyan', label='GEN sel.', **opts)[0]\n",
    "genbhist = plt.hist(mc['log_genBefore_thrust'], color='green', label='GEN before', **opts)[0]\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylim(10**-5.5, 1)\n",
    "\n",
    "plt.xlabel(r'$\\ln(1-T)$')\n",
    "plt.ylabel('Probability Density')\n",
    "\n",
    "plt.legend(loc=(0.425, 0.025), frameon=False)\n",
    "\n",
    "plt.savefig('../plots/LogThrustDistributions.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the Unfolding Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many iterations of the unfolding process\n",
    "itnum = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the observables to use for multifold (a single one just indicates unifold)\n",
    "obs_multifold = ['LogThrust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary to hold information about the observables\n",
    "obs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the thrust and histogram style information\n",
    "#obs.setdefault('Thrust', {}).update({\n",
    "#    'func': lambda dset, ptype: dset[ptype + '_thrust'],\n",
    "#    'nbins_det': 50, 'nbins_mc': 50,\n",
    "#    'yscale': 'log',\n",
    "#    'xlim': (0, 0.5), 'ylim': (10**-4.5, 100), 'ylim_ratio': (0.7, 1.3),\n",
    "#    'ytick_ratio_step': 0.15,\n",
    "#    'xlabel': r'Thrust $\\tau$', 'symbol': r'$\\tau$',\n",
    "#    'ylabel': r'Normalized Cross Section', 'ylabel_ratio': 'Ratio to\\nALEPH',\n",
    "#    'stamp_xy': (0.5, 0.9),\n",
    "#    'legend_loc': 'lower left', 'legend_ncol': 1\n",
    "#})\n",
    "\n",
    "obs.setdefault('LogThrust', {}).update({\n",
    "    'func': lambda dset, ptype: dset[ptype + '_thrust'],\n",
    "    'nbins_det': 50, 'nbins_mc': 50,\n",
    "    'yscale': 'log',\n",
    "    'xlim': (-8, np.log(0.5)), 'ylim': (10**-5.5, 1), 'ylim_ratio': (0.7, 1.3),\n",
    "    'ytick_ratio_step': 0.15,\n",
    "    'xlabel': r'Thrust $\\ln(1-T)$', 'symbol': r'$\\ln(1-T)$',\n",
    "    'ylabel': r'Normalized Cross Section', 'ylabel_ratio': 'Ratio to\\nGen.',\n",
    "    'stamp_xy': (0.5, 0.9),\n",
    "    'legend_loc': 'lower left', 'legend_ncol': 1\n",
    "})\n",
    "\n",
    "# additional histogram and plot style information\n",
    "hist_style = {'histtype': 'step', 'density': True, 'lw': 1, 'zorder': 2}\n",
    "gen_style = {'linestyle': '--', 'color': 'blue', 'lw': 1.15, 'label': r'\\textsc{Pythia} 6 Gen.'}\n",
    "truth_style = {'step': 'mid', 'edgecolor': 'green', 'facecolor': (0.75, 0.875, 0.75),\n",
    "               'lw': 1.25, 'zorder': 0, 'label': 'ALEPH Measurement'}\n",
    "ibu_style = {'ls': '-', 'marker': 'o', 'ms': 2.5, 'color': 'gray', 'zorder': 1}\n",
    "omnifold_style = {'ls': '-', 'marker': 's', 'ms': 2.5, 'color': 'tab:red', 'zorder': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LogThrust\n"
     ]
    }
   ],
   "source": [
    "# calculate quantities to be stored in obs\n",
    "for obkey,ob in obs.items():\n",
    "    \n",
    "    # calculate observable for GEN, SIM, DATA, and TRUE\n",
    "    ob['genobs'], ob['simobs'] = ob['func'](synthetic, 'gen'), ob['func'](synthetic, 'sim')\n",
    "    ob['dataobs'] = ob['func'](nature, 'data')\n",
    "    \n",
    "    # setup bins\n",
    "    ob['bins_det'] = np.linspace(ob['xlim'][0], ob['xlim'][1], ob['nbins_det']+1)\n",
    "    ob['bins_mc'] = np.linspace(ob['xlim'][0], ob['xlim'][1], ob['nbins_mc']+1)\n",
    "    ob['midbins_det'] = (ob['bins_det'][:-1] + ob['bins_det'][1:])/2\n",
    "    ob['midbins_mc'] = (ob['bins_mc'][:-1] + ob['bins_mc'][1:])/2\n",
    "    ob['binwidth_det'] = ob['bins_det'][1] - ob['bins_det'][0]\n",
    "    ob['binwidth_mc'] = ob['bins_mc'][1] - ob['bins_mc'][0]\n",
    "    \n",
    "    # get the histograms of GEN, DATA, and TRUTH level observables\n",
    "    ob['genobs_hist'] = np.histogram(ob['genobs'], bins=ob['bins_mc'], density=True)[0]\n",
    "    ob['data_hist'] = np.histogram(ob['dataobs'], bins=ob['bins_det'], density=True)[0]\n",
    "\n",
    "    # compute (and normalize) the response matrix between GEN and SIM\n",
    "    ob['response'] = np.histogram2d(ob['simobs'], ob['genobs'], bins=(ob['bins_det'], ob['bins_mc']))[0]\n",
    "    ob['response'] /= (ob['response'].sum(axis=0) + 10**-50)\n",
    "    \n",
    "    # perform iterative Bayesian unfolding\n",
    "    ob['ibu_phis'] = ibu.ibu(ob['data_hist'], ob['response'], ob['genobs_hist'], \n",
    "                             ob['binwidth_det'], ob['binwidth_mc'], it=itnum)\n",
    "    ob['ibu_phi_unc'] = ibu.ibu_unc(ob, it=itnum, nresamples=50)\n",
    "    \n",
    "    print('Done with', obkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OmniFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_layer_sizes = [100, 100, 100]\n",
    "val = 0.2\n",
    "\n",
    "# set up the array of data/simulation detector-level observables\n",
    "ob0 = obs_multifold[0]\n",
    "X_det = np.asarray([np.concatenate((obs[obkey]['dataobs'], obs[obkey]['simobs'])) for obkey in obs_multifold]).T\n",
    "Y_det = ef.utils.to_categorical(np.concatenate((np.ones(len(obs[ob0]['dataobs'])), \n",
    "                                                np.zeros(len(obs[ob0]['simobs'])))))\n",
    "\n",
    "# set up the array of generation particle-level observables\n",
    "X_gen = np.asarray([np.concatenate((obs[obkey]['genobs'], obs[obkey]['genobs'])) for obkey in obs_multifold]).T\n",
    "Y_gen = ef.utils.to_categorical(np.concatenate((np.ones(len(obs[ob0]['genobs'])), \n",
    "                                                np.zeros(len(obs[ob0]['genobs'])))))\n",
    "\n",
    "# standardize the inputs\n",
    "X_det = (X_det - np.mean(X_det, axis=0))/np.std(X_det, axis=0)\n",
    "X_gen = (X_gen - np.mean(X_gen, axis=0))/np.std(X_gen, axis=0)\n",
    "\n",
    "# reweight the sim and data to have the same total weight to begin with\n",
    "ndata, nsim = np.count_nonzero(Y_det[:,1]), np.count_nonzero(Y_det[:,0])\n",
    "wdata = np.ones(ndata)\n",
    "winit = ndata/nsim*np.ones(nsim)\n",
    "\n",
    "# initialize the truth weights to the prior\n",
    "ws = [winit]\n",
    "\n",
    "# get permutation for det\n",
    "perm_det = np.random.permutation(len(winit) + len(wdata))\n",
    "invperm_det = np.argsort(perm_det)\n",
    "nval_det = int(val*len(perm_det))\n",
    "X_det_train, X_det_val = X_det[perm_det[:-nval_det]], X_det[perm_det[-nval_det:]]\n",
    "Y_det_train, Y_det_val = Y_det[perm_det[:-nval_det]], Y_det[perm_det[-nval_det:]]\n",
    "del X_det, Y_det\n",
    "\n",
    "# get an initial permutation for gen and duplicate (offset) it\n",
    "nval = int(val*len(winit))\n",
    "baseperm0 = np.random.permutation(len(winit))\n",
    "baseperm1 = baseperm0 + len(winit)\n",
    "\n",
    "# training examples are at beginning, val at end\n",
    "# concatenate into single train and val perms (shuffle each)\n",
    "trainperm = np.concatenate((baseperm0[:-nval], baseperm1[:-nval]))\n",
    "valperm = np.concatenate((baseperm0[-nval:], baseperm1[-nval:]))\n",
    "np.random.shuffle(trainperm)\n",
    "np.random.shuffle(valperm)\n",
    "\n",
    "# get final permutation for gen (ensured that the same events end up in val)\n",
    "perm_gen = np.concatenate((trainperm, valperm))\n",
    "invperm_gen = np.argsort(perm_gen)\n",
    "nval_gen = 2*nval\n",
    "X_gen_train, X_gen_val = X_gen[perm_gen[:-nval_gen]], X_gen[perm_gen[-nval_gen:]]\n",
    "Y_gen_train, Y_gen_val = Y_gen[perm_gen[:-nval_gen]], Y_gen[perm_gen[-nval_gen:]]\n",
    "del X_gen, Y_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCTR, reweights positive distribution to negative distribution\n",
    "# X: features\n",
    "# Y: categorical labels\n",
    "# model: model with fit/predict\n",
    "# fitargs: model fit arguments\n",
    "def reweight(X, Y, w, model, filepath, fitargs, val_data=None):\n",
    "\n",
    "    val_dict = {'validation_data': val_data} if val_data is not None else {}\n",
    "    model.fit(X, Y, sample_weight=w, **fitargs, **val_dict)\n",
    "    model.save_weights(filepath)\n",
    "    preds = model.predict(X, batch_size=10000)[:,1]\n",
    "    \n",
    "    # concatenate validation predictions into training predictions\n",
    "    if val_data is not None:\n",
    "        preds_val = model.predict(val_data[0], batch_size=10000)[:,1]\n",
    "        preds = np.concatenate((preds, preds_val))\n",
    "        w = np.concatenate((w, val_data[2]))\n",
    "\n",
    "    w *= preds/(1 - preds + 10**-50)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfolding iteration 0\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonybadea/anaconda3/envs/rpv_multijet/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonybadea/anaconda3/envs/rpv_multijet/lib/python3.8/site-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662570/1662570 - 5s - loss: 0.8877 - acc: 0.5186 - val_loss: 0.8897 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 5s - loss: 0.8854 - acc: 0.5298 - val_loss: 0.8842 - val_acc: 0.4652 - 5s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 5s - loss: 0.8850 - acc: 0.5352 - val_loss: 0.8842 - val_acc: 0.5805 - 5s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.5111 - val_loss: 0.8842 - val_acc: 0.4703 - 5s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.5124 - val_loss: 0.8841 - val_acc: 0.5124 - 5s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.5344 - val_loss: 0.8842 - val_acc: 0.5525 - 5s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.5118 - val_loss: 0.8844 - val_acc: 0.6236 - 5s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.5349 - val_loss: 0.8842 - val_acc: 0.5911 - 5s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.5420 - val_loss: 0.8842 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.4779 - val_loss: 0.8842 - val_acc: 0.3707 - 5s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.4772 - val_loss: 0.8842 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.4836 - val_loss: 0.8842 - val_acc: 0.5179 - 5s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.5194 - val_loss: 0.8842 - val_acc: 0.5526 - 5s/epoch - 3us/sample\n",
      "Epoch 14/100\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.4947 - val_loss: 0.8842 - val_acc: 0.5736 - 5s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "1662570/1662570 - 5s - loss: 0.8849 - acc: 0.5061 - val_loss: 0.8841 - val_acc: 0.5213 - 5s/epoch - 3us/sample\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonybadea/anaconda3/envs/rpv_multijet/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2232 - acc: 0.5004 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2216 - acc: 0.4997 - val_loss: 1.2206 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2208 - acc: 0.5001 - val_loss: 1.2206 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2206 - acc: 0.4996 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5003 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4998 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5001 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4996 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5004 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4988 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4996 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5002 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4994 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 14/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4990 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4999 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 16/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4998 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 17/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4999 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 18/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4999 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 19/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4999 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 20/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5006 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 21/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5000 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 22/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5011 - val_loss: 1.2206 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 23/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5006 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 24/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4991 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 25/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5001 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 26/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5002 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 27/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4991 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 28/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4999 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 29/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4999 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 30/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4994 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 31/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4995 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 32/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.5004 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 33/100\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4993 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 34/100\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "1202978/1202978 - 4s - loss: 1.2205 - acc: 0.4994 - val_loss: 1.2205 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 00034: early stopping\n",
      "Unfolding iteration 1\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Step 1 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw0_Step-1_Iteration-0\n",
      "Step 2 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw0_Step-2_Iteration-0\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5235 - val_loss: 0.8828 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5318 - val_loss: 0.8828 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5412 - val_loss: 0.8828 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5351 - val_loss: 0.8828 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5287 - val_loss: 0.8828 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5083 - val_loss: 0.8828 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5465 - val_loss: 0.8828 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5355 - val_loss: 0.8828 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5134 - val_loss: 0.8828 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 5s - loss: 0.8835 - acc: 0.5495 - val_loss: 0.8828 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "1662570/1662570 - 6s - loss: 0.8835 - acc: 0.5249 - val_loss: 0.8828 - val_acc: 0.6392 - 6s/epoch - 3us/sample\n",
      "Epoch 00011: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4998 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.5006 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4993 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4996 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4993 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4996 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.5001 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4995 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4999 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4996 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4993 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4997 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4999 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 14/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4993 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.4996 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 16/100\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "1202978/1202978 - 4s - loss: 1.2260 - acc: 0.5001 - val_loss: 1.2260 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 00016: early stopping\n",
      "Unfolding iteration 2\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Step 1 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw0_Step-1_Iteration-1\n",
      "Step 2 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw0_Step-2_Iteration-1\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4286 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4071 - val_loss: 0.8867 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4037 - val_loss: 0.8867 - val_acc: 0.3608 - 6s/epoch - 4us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.3951 - val_loss: 0.8867 - val_acc: 0.6392 - 6s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4258 - val_loss: 0.8867 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4210 - val_loss: 0.8867 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4219 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4016 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4125 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4043 - val_loss: 0.8867 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4154 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.3926 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4009 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4061 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "1662570/1662570 - 5s - loss: 0.8873 - acc: 0.4208 - val_loss: 0.8867 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 00015: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5000 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5003 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5003 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.4999 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.4995 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5000 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.4998 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5006 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.4997 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5000 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.4998 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5001 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.4989 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 14/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5005 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.4997 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 16/100\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.5000 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 17/100\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "1202978/1202978 - 4s - loss: 1.2251 - acc: 0.4992 - val_loss: 1.2251 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 00017: early stopping\n",
      "Unfolding iteration 3\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Step 1 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw0_Step-1_Iteration-2\n",
      "Step 2 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw0_Step-2_Iteration-2\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4289 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4215 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4511 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4306 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4406 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4399 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4418 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4338 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4288 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4110 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4158 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "1662570/1662570 - 5s - loss: 0.8864 - acc: 0.4131 - val_loss: 0.8857 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 00012: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.4996 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.5004 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.5000 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.4995 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.5003 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.5001 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.5008 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.4996 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.4999 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.5001 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.5012 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "1202978/1202978 - 4s - loss: 1.2246 - acc: 0.5003 - val_loss: 1.2246 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 00012: early stopping\n",
      "Unfolding iteration 4\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_37 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_38 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_39 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Step 1 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw0_Step-1_Iteration-3\n",
      "Step 2 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw0_Step-2_Iteration-3\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 6s - loss: 0.8865 - acc: 0.4159 - val_loss: 0.8859 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4255 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 6s - loss: 0.8865 - acc: 0.4194 - val_loss: 0.8858 - val_acc: 0.6392 - 6s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4383 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4241 - val_loss: 0.8858 - val_acc: 0.6392 - 5s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4328 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4111 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4167 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4082 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4198 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4088 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4309 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "1662570/1662570 - 5s - loss: 0.8865 - acc: 0.4312 - val_loss: 0.8858 - val_acc: 0.3608 - 5s/epoch - 3us/sample\n",
      "Epoch 00013: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4997 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4999 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4997 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5002 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5001 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4999 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4997 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5000 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5005 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5002 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5001 - val_loss: 1.2256 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5003 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4999 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 14/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4998 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5001 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 16/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4996 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4998 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 18/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5000 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 19/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5005 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 20/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4997 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 21/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5003 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 22/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4999 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 23/100\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4997 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 00023: early stopping\n",
      "Unfolding iteration 0\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_40 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_41 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 6s - loss: 0.8889 - acc: 0.5097 - val_loss: 0.8872 - val_acc: 0.5098 - 6s/epoch - 3us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 6s - loss: 0.8877 - acc: 0.5059 - val_loss: 0.8866 - val_acc: 0.5373 - 6s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4992 - val_loss: 0.8866 - val_acc: 0.4553 - 6s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4693 - val_loss: 0.8866 - val_acc: 0.5058 - 6s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4687 - val_loss: 0.8866 - val_acc: 0.4344 - 6s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4878 - val_loss: 0.8866 - val_acc: 0.4420 - 6s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4756 - val_loss: 0.8866 - val_acc: 0.4477 - 6s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4814 - val_loss: 0.8866 - val_acc: 0.5409 - 6s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4898 - val_loss: 0.8867 - val_acc: 0.4182 - 6s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4928 - val_loss: 0.8866 - val_acc: 0.5364 - 6s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.4984 - val_loss: 0.8866 - val_acc: 0.5279 - 6s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.5063 - val_loss: 0.8866 - val_acc: 0.5622 - 6s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.5188 - val_loss: 0.8866 - val_acc: 0.4859 - 6s/epoch - 3us/sample\n",
      "Epoch 14/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.5105 - val_loss: 0.8866 - val_acc: 0.4809 - 6s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.5086 - val_loss: 0.8866 - val_acc: 0.5389 - 6s/epoch - 3us/sample\n",
      "Epoch 16/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.5123 - val_loss: 0.8866 - val_acc: 0.5480 - 6s/epoch - 3us/sample\n",
      "Epoch 17/100\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.5132 - val_loss: 0.8866 - val_acc: 0.5409 - 6s/epoch - 3us/sample\n",
      "Epoch 18/100\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "1662570/1662570 - 6s - loss: 0.8873 - acc: 0.5082 - val_loss: 0.8866 - val_acc: 0.5045 - 6s/epoch - 3us/sample\n",
      "Epoch 00018: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2362 - acc: 0.4997 - val_loss: 1.2337 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2329 - acc: 0.5004 - val_loss: 1.2328 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2321 - acc: 0.4999 - val_loss: 1.2320 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.5000 - val_loss: 1.2316 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2316 - acc: 0.5000 - val_loss: 1.2319 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.4993 - val_loss: 1.2316 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.4999 - val_loss: 1.2316 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.4991 - val_loss: 1.2316 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.5001 - val_loss: 1.2316 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.5000 - val_loss: 1.2316 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.4999 - val_loss: 1.2317 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.5002 - val_loss: 1.2316 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1202978/1202978 - 4s - loss: 1.2317 - acc: 0.5003 - val_loss: 1.2316 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "1202978/1202978 - 5s - loss: 1.2317 - acc: 0.4995 - val_loss: 1.2316 - val_acc: 0.5000 - 5s/epoch - 4us/sample\n",
      "Epoch 00014: early stopping\n",
      "Unfolding iteration 1\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_51 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_52 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_53 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_54 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_55 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Step 1 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw-2_Step-1_Iteration-0\n",
      "Step 2 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw-2_Step-2_Iteration-0\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.4563 - val_loss: 0.8878 - val_acc: 0.4063 - 6s/epoch - 4us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.4180 - val_loss: 0.8878 - val_acc: 0.6332 - 6s/epoch - 4us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3931 - val_loss: 0.8878 - val_acc: 0.3608 - 6s/epoch - 4us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3927 - val_loss: 0.8878 - val_acc: 0.6392 - 6s/epoch - 4us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3827 - val_loss: 0.8878 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3753 - val_loss: 0.8878 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3914 - val_loss: 0.8878 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3810 - val_loss: 0.8878 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3832 - val_loss: 0.8878 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3911 - val_loss: 0.8878 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "1662570/1662570 - 6s - loss: 0.8885 - acc: 0.3772 - val_loss: 0.8878 - val_acc: 0.3608 - 6s/epoch - 3us/sample\n",
      "Epoch 00011: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5001 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5001 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4997 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5000 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5000 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4998 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4998 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4999 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4999 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4998 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5001 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.4999 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "1202978/1202978 - 4s - loss: 1.2255 - acc: 0.5001 - val_loss: 1.2255 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 00013: early stopping\n",
      "Unfolding iteration 2\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_58 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_59 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Step 1 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw-2_Step-1_Iteration-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw-2_Step-2_Iteration-1\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 6s - loss: 0.8839 - acc: 0.5279 - val_loss: 0.8832 - val_acc: 0.5876 - 6s/epoch - 4us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 6s - loss: 0.8839 - acc: 0.5285 - val_loss: 0.8832 - val_acc: 0.6023 - 6s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 6s - loss: 0.8839 - acc: 0.5367 - val_loss: 0.8833 - val_acc: 0.5644 - 6s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 6s - loss: 0.8839 - acc: 0.5316 - val_loss: 0.8832 - val_acc: 0.6204 - 6s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 6s - loss: 0.8838 - acc: 0.5230 - val_loss: 0.8832 - val_acc: 0.5974 - 6s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 6s - loss: 0.8838 - acc: 0.5207 - val_loss: 0.8832 - val_acc: 0.6027 - 6s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 6s - loss: 0.8838 - acc: 0.5285 - val_loss: 0.8832 - val_acc: 0.5908 - 6s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 6s - loss: 0.8838 - acc: 0.5385 - val_loss: 0.8832 - val_acc: 0.6077 - 6s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 6s - loss: 0.8838 - acc: 0.5292 - val_loss: 0.8832 - val_acc: 0.6340 - 6s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 6s - loss: 0.8838 - acc: 0.5383 - val_loss: 0.8832 - val_acc: 0.4405 - 6s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1662570/1662570 - 6s - loss: 0.8838 - acc: 0.5318 - val_loss: 0.8832 - val_acc: 0.4510 - 6s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "1662570/1662570 - 6s - loss: 0.8838 - acc: 0.5331 - val_loss: 0.8832 - val_acc: 0.4419 - 6s/epoch - 4us/sample\n",
      "Epoch 00012: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.5003 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4998 - val_loss: 1.2232 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.5002 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4999 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4992 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4998 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.5000 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.5007 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4996 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4995 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4995 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4998 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.5006 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 14/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4996 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4999 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 16/100\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "1202978/1202978 - 4s - loss: 1.2231 - acc: 0.4999 - val_loss: 1.2231 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 00016: early stopping\n",
      "Unfolding iteration 3\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_65 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_66 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_67 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_68 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_69 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_70 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_71 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Step 1 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw-2_Step-1_Iteration-2\n",
      "Step 2 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw-2_Step-2_Iteration-2\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4611 - val_loss: 0.8866 - val_acc: 0.4016 - 6s/epoch - 4us/sample\n",
      "Epoch 2/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4555 - val_loss: 0.8866 - val_acc: 0.4532 - 6s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4588 - val_loss: 0.8866 - val_acc: 0.4436 - 6s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4591 - val_loss: 0.8866 - val_acc: 0.4193 - 6s/epoch - 3us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4612 - val_loss: 0.8866 - val_acc: 0.4159 - 6s/epoch - 3us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4501 - val_loss: 0.8866 - val_acc: 0.5668 - 6s/epoch - 3us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4588 - val_loss: 0.8866 - val_acc: 0.4231 - 6s/epoch - 3us/sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4603 - val_loss: 0.8866 - val_acc: 0.4248 - 6s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4671 - val_loss: 0.8866 - val_acc: 0.4396 - 6s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4608 - val_loss: 0.8866 - val_acc: 0.4283 - 6s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4589 - val_loss: 0.8866 - val_acc: 0.4355 - 6s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4547 - val_loss: 0.8866 - val_acc: 0.6003 - 6s/epoch - 3us/sample\n",
      "Epoch 13/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4654 - val_loss: 0.8867 - val_acc: 0.4259 - 6s/epoch - 3us/sample\n",
      "Epoch 14/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4632 - val_loss: 0.8866 - val_acc: 0.4423 - 6s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4572 - val_loss: 0.8866 - val_acc: 0.4404 - 6s/epoch - 3us/sample\n",
      "Epoch 16/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4652 - val_loss: 0.8866 - val_acc: 0.4200 - 6s/epoch - 3us/sample\n",
      "Epoch 17/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4560 - val_loss: 0.8866 - val_acc: 0.6028 - 6s/epoch - 3us/sample\n",
      "Epoch 18/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4634 - val_loss: 0.8866 - val_acc: 0.5989 - 6s/epoch - 3us/sample\n",
      "Epoch 19/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4631 - val_loss: 0.8866 - val_acc: 0.4247 - 6s/epoch - 4us/sample\n",
      "Epoch 20/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4538 - val_loss: 0.8866 - val_acc: 0.5865 - 6s/epoch - 4us/sample\n",
      "Epoch 21/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4655 - val_loss: 0.8866 - val_acc: 0.4110 - 6s/epoch - 4us/sample\n",
      "Epoch 22/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4616 - val_loss: 0.8866 - val_acc: 0.4024 - 6s/epoch - 4us/sample\n",
      "Epoch 23/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4639 - val_loss: 0.8866 - val_acc: 0.3979 - 6s/epoch - 3us/sample\n",
      "Epoch 24/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4557 - val_loss: 0.8866 - val_acc: 0.4271 - 6s/epoch - 3us/sample\n",
      "Epoch 25/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4581 - val_loss: 0.8866 - val_acc: 0.4006 - 6s/epoch - 3us/sample\n",
      "Epoch 26/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4550 - val_loss: 0.8866 - val_acc: 0.4335 - 6s/epoch - 3us/sample\n",
      "Epoch 27/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4526 - val_loss: 0.8866 - val_acc: 0.4201 - 6s/epoch - 3us/sample\n",
      "Epoch 28/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4555 - val_loss: 0.8866 - val_acc: 0.6021 - 6s/epoch - 3us/sample\n",
      "Epoch 29/100\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4670 - val_loss: 0.8866 - val_acc: 0.4213 - 6s/epoch - 3us/sample\n",
      "Epoch 30/100\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "1662570/1662570 - 6s - loss: 0.8872 - acc: 0.4605 - val_loss: 0.8866 - val_acc: 0.4343 - 6s/epoch - 4us/sample\n",
      "Epoch 00030: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.4996 - val_loss: 1.2306 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.5000 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.5008 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.5000 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.4995 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.5005 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.5004 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.5008 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.5000 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.5000 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.4998 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 12/100\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "1202978/1202978 - 4s - loss: 1.2306 - acc: 0.4999 - val_loss: 1.2305 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 00012: early stopping\n",
      "Unfolding iteration 4\n",
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_72 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_73 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_74 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_75 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_0 (Dense)             (None, 100)               200       \n",
      "                                                                 \n",
      " activation_76 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_77 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " activation_78 (Activation)  (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      " activation_79 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Step 1 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw-2_Step-1_Iteration-3\n",
      "Step 2 - loading weights from ptktraining/LogThrustUnifold_patience-10_batchsize-500_trw-2_Step-2_Iteration-3\n",
      "Train on 1662570 samples, validate on 415642 samples\n",
      "Epoch 1/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4608 - val_loss: 0.8871 - val_acc: 0.4509 - 6s/epoch - 4us/sample\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662570/1662570 - 6s - loss: 0.8877 - acc: 0.4579 - val_loss: 0.8871 - val_acc: 0.4314 - 6s/epoch - 3us/sample\n",
      "Epoch 3/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4478 - val_loss: 0.8871 - val_acc: 0.4300 - 6s/epoch - 4us/sample\n",
      "Epoch 4/100\n",
      "1662570/1662570 - 6s - loss: 0.8877 - acc: 0.4522 - val_loss: 0.8871 - val_acc: 0.5950 - 6s/epoch - 4us/sample\n",
      "Epoch 5/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4544 - val_loss: 0.8871 - val_acc: 0.4095 - 6s/epoch - 4us/sample\n",
      "Epoch 6/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4481 - val_loss: 0.8871 - val_acc: 0.4302 - 6s/epoch - 4us/sample\n",
      "Epoch 7/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4539 - val_loss: 0.8874 - val_acc: 0.3938 - 6s/epoch - 4us/sample\n",
      "Epoch 8/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4474 - val_loss: 0.8871 - val_acc: 0.4275 - 6s/epoch - 3us/sample\n",
      "Epoch 9/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4476 - val_loss: 0.8871 - val_acc: 0.6113 - 6s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4570 - val_loss: 0.8871 - val_acc: 0.5845 - 6s/epoch - 4us/sample\n",
      "Epoch 11/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4586 - val_loss: 0.8871 - val_acc: 0.6126 - 6s/epoch - 4us/sample\n",
      "Epoch 12/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4533 - val_loss: 0.8871 - val_acc: 0.5924 - 6s/epoch - 4us/sample\n",
      "Epoch 13/100\n",
      "1662570/1662570 - 6s - loss: 0.8877 - acc: 0.4625 - val_loss: 0.8871 - val_acc: 0.4192 - 6s/epoch - 4us/sample\n",
      "Epoch 14/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4451 - val_loss: 0.8871 - val_acc: 0.4322 - 6s/epoch - 3us/sample\n",
      "Epoch 15/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4570 - val_loss: 0.8871 - val_acc: 0.4277 - 6s/epoch - 3us/sample\n",
      "Epoch 16/100\n",
      "1662570/1662570 - 6s - loss: 0.8877 - acc: 0.4596 - val_loss: 0.8871 - val_acc: 0.4224 - 6s/epoch - 4us/sample\n",
      "Epoch 17/100\n",
      "1662570/1662570 - 6s - loss: 0.8877 - acc: 0.4544 - val_loss: 0.8871 - val_acc: 0.4088 - 6s/epoch - 4us/sample\n",
      "Epoch 18/100\n",
      "1662570/1662570 - 6s - loss: 0.8877 - acc: 0.4665 - val_loss: 0.8871 - val_acc: 0.4117 - 6s/epoch - 4us/sample\n",
      "Epoch 19/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4452 - val_loss: 0.8871 - val_acc: 0.4193 - 6s/epoch - 3us/sample\n",
      "Epoch 20/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4507 - val_loss: 0.8871 - val_acc: 0.4198 - 6s/epoch - 3us/sample\n",
      "Epoch 21/100\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4525 - val_loss: 0.8871 - val_acc: 0.5844 - 6s/epoch - 3us/sample\n",
      "Epoch 22/100\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "1662570/1662570 - 6s - loss: 0.8878 - acc: 0.4555 - val_loss: 0.8871 - val_acc: 0.4358 - 6s/epoch - 4us/sample\n",
      "Epoch 00022: early stopping\n",
      "Train on 1202978 samples, validate on 300744 samples\n",
      "Epoch 1/100\n",
      "1202978/1202978 - 5s - loss: 1.2312 - acc: 0.4997 - val_loss: 1.2312 - val_acc: 0.5000 - 5s/epoch - 4us/sample\n",
      "Epoch 2/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4998 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 3/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.5000 - val_loss: 1.2313 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 4/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4998 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 5/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4999 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 6/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.5009 - val_loss: 1.2313 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 7/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4996 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 8/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.5004 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 9/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4996 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 3us/sample\n",
      "Epoch 10/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.5001 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 11/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4999 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 12/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4988 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 13/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4998 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 14/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4995 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 15/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.5000 - val_loss: 1.2313 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 16/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4995 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 17/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4995 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 18/100\n",
      "1202978/1202978 - 4s - loss: 1.2312 - acc: 0.4999 - val_loss: 1.2312 - val_acc: 0.5000 - 4s/epoch - 4us/sample\n",
      "Epoch 19/100\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "1202978/1202978 - 5s - loss: 1.2312 - acc: 0.4993 - val_loss: 1.2312 - val_acc: 0.5000 - 5s/epoch - 4us/sample\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "for trw_ind in [0, -2]:\n",
    "\n",
    "    name = 'LogThrustUnifold_patience-10_batchsize-500_trw{}'.format(trw_ind)\n",
    "    fitargs = {'epochs': 100, 'batch_size': 500, 'verbose': 2}\n",
    "\n",
    "    # iterative unfolding\n",
    "    for i in range(itnum):\n",
    "        print('Unfolding iteration', i)\n",
    "\n",
    "        model_det_fp = 'ptktraining/{}_Step-1_Iteration-{}'.format(name, '{}')\n",
    "        model_mc_fp = 'ptktraining/{}_Step-2_Iteration-{}'.format(name, '{}')\n",
    "\n",
    "        # define detector reweighting model\n",
    "        model_det = ef.archs.DNN(input_dim=len(obs_multifold), dense_sizes=model_layer_sizes, patience=10,\n",
    "                                 #filepath=model_det_fp.format(i) + '_Epoch-{epoch}',\n",
    "                                 optimizer=Adam(lr=0.0005))\n",
    "\n",
    "        # define particle reweighting model\n",
    "        model_mc = ef.archs.DNN(input_dim=len(obs_multifold), dense_sizes=model_layer_sizes, patience=10,\n",
    "                                #filepath=model_mc_fp.format(i) + '_Epoch-{epoch}',\n",
    "                                optimizer=Adam(lr=0.0005))\n",
    "\n",
    "        # load wieghts if not iteration 0\n",
    "        if i > 0:\n",
    "            print('Step 1 - loading weights from', model_det_fp.format(i-1))\n",
    "            model_det.load_weights(model_det_fp.format(i-1))\n",
    "\n",
    "            print('Step 2 - loading weights from', model_mc_fp.format(i-1))\n",
    "            model_mc.load_weights(model_mc_fp.format(i-1))\n",
    "\n",
    "        # step 1: reweight sim to look like data\n",
    "        w = np.concatenate((wdata, ws[-1]))\n",
    "        w_train, w_val = w[perm_det[:-nval_det]], w[perm_det[-nval_det:]]\n",
    "        rw = reweight(X_det_train, Y_det_train, w_train, model_det, model_det_fp.format(i),\n",
    "                      fitargs, val_data=(X_det_val, Y_det_val, w_val))[invperm_det]\n",
    "        ws.append(rw[len(wdata):])\n",
    "\n",
    "        # step 2: reweight the prior to the learned weighting\n",
    "        w = np.concatenate((ws[-1], ws[trw_ind]))\n",
    "        w_train, w_val = w[perm_gen[:-nval_gen]], w[perm_gen[-nval_gen:]]\n",
    "        rw = reweight(X_gen_train, Y_gen_train, w_train, model_mc, model_mc_fp.format(i),\n",
    "                      fitargs, val_data=(X_gen_val, Y_gen_val, w_val))[invperm_gen]\n",
    "        ws.append(rw[len(ws[-1]):])\n",
    "\n",
    "        # save the weights if specified\n",
    "        np.save(name, ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Unfolding Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THRUST,THRUST LOW,THRUST HIGH,(1/SIG)*D(SIG)/DTHRUST,stat +,stat -,sys_1 +,sys_1 -,sys_2 +,sys_2 -\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(aleph_path,'HEPData-ins636645-v1-Table_54.csv'), 'r') as f:\n",
    "    \n",
    "    vals = []\n",
    "    for row in f:\n",
    "        if row.startswith('#'):\n",
    "            continue\n",
    "            \n",
    "        if row.startswith('T'):\n",
    "            print(row.strip())\n",
    "        else:\n",
    "            vals.append(row.strip().split(','))\n",
    "            \n",
    "hepdata = np.asarray(vals, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "aleph_bins = 1 - np.append(1.0, hepdata[::-1,1])\n",
    "aleph_midbins = (aleph_bins[1:] + aleph_bins[:-1])/2\n",
    "aleph_thrust = hepdata[::-1,3]\n",
    "aleph_thrust_errs = np.linalg.norm(hepdata[::-1,[-1,-3,-5]], axis=1)\n",
    "assert np.all(aleph_bins[1:] == 1 - hepdata[::-1,1]) and np.all(aleph_bins[:-1] == 1 - hepdata[::-1,2])\n",
    "\n",
    "plt.errorbar(aleph_midbins, aleph_thrust, xerr=0.005, yerr=aleph_thrust_errs, label='ALEPH Eur.Phys.J. C (2004) 457-486',\n",
    "             color='green', **modplot.style('errorbar'))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Thrust $1 - T$')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend(loc='lower left', frameon=False)\n",
    "plt.show()\n",
    "\n",
    "aleph_log_bins = np.log(aleph_bins + np.exp(-8))\n",
    "aleph_log_midbins = (aleph_log_bins[1:] + aleph_log_bins[:-1])/2\n",
    "log_binwidths = aleph_log_bins[1:] - aleph_log_bins[:-1]\n",
    "aleph_log_thrust = aleph_thrust * 0.01 / log_binwidths\n",
    "aleph_log_thrust_errs = aleph_thrust_errs * 0.01 / log_binwidths\n",
    "\n",
    "plt.errorbar(aleph_log_midbins, aleph_log_thrust, color='green', label='ALEPH Measurement',\n",
    "             xerr=log_binwidths/2, yerr=aleph_log_thrust_errs, **modplot.style('errorbar'))\n",
    "plt.yscale('log')\n",
    "plt.xlim(-8, 0)\n",
    "plt.ylim(10**-4, 1)\n",
    "plt.xlabel(r'Thrust $\\ln(1 - T)$')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend(loc='lower left', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "obkey = 'LogThrust'\n",
    "ob = obs['LogThrust']\n",
    "corrs = np.ones(genbhist.shape)\n",
    "corrs = genbhist/(genhist + 10**-50)\n",
    "\n",
    "# convert obs to numpy\n",
    "ob[\"genobs\"] = np.array(ob[\"genobs\"])\n",
    "ob[\"dataobs\"] = np.array(ob[\"dataobs\"])\n",
    "ob[\"simobs\"] = np.array(ob[\"simobs\"])\n",
    "\n",
    "omnifold_ws = np.load('LogThrustUnifold_patience-10_batchsize-500_trw0.npy')\n",
    "#omnifold_ws = np.load('LogThrustUnifold.npy')\n",
    "\n",
    "fig, [ax0, ax1] = modplot.axes(**ob, gridspec_update={'height_ratios': (3, 1)})\n",
    "if ob.get('yscale') is not None:\n",
    "    ax0.set_yscale(ob['yscale'])\n",
    "\n",
    "# plot the \"data\" histogram of the observable\n",
    "ax0.hist(ob['dataobs'], bins=ob['bins_det'], color='black', label='ALEPH Raw 1994 Data', **hist_style)\n",
    "\n",
    "# plot the \"sim\" histogram of the observable\n",
    "ax0.hist(ob['simobs'], bins=ob['bins_det'], color='orange', label='Pythia 6 + Geant 3 Sim.', **hist_style)\n",
    "\n",
    "# plot the \"gen\" histogram of the observable\n",
    "ax0.plot(ob['midbins_mc'], ob['genobs_hist'], **gen_style)\n",
    "\n",
    "# plot the IBU distribution\n",
    "ibu_hist = ob['ibu_phis'][itnum]*corrs\n",
    "ax0.errorbar(ob['midbins_mc'], ibu_hist, xerr=ob['binwidth_mc']/2, yerr=ob['ibu_phi_unc']*corrs,\n",
    "             color='gray', label='IBU {} + stat.'.format(ob['symbol']), **modplot.style('errorbar'))\n",
    "\n",
    "# plot the UniFold distribution\n",
    "omnifold_hist, omnifold_errs = modplot.calc_hist(ob['genobs'], bins=ob['bins_mc'], \n",
    "                                                 weights=omnifold_ws[-5], density=True)[:2]\n",
    "ax0.errorbar(ob['midbins_mc'], omnifold_hist, xerr=ob['binwidth_mc']/2, yerr=omnifold_errs*corrs,\n",
    "             color='tab:red', label='UniFold {} + stat.'.format(ob['symbol']), **modplot.style('errorbar'))\n",
    "\n",
    "# plot the ALEPH measurement\n",
    "ax0.errorbar(aleph_log_midbins, aleph_log_thrust, color='green', label='ALEPH E.P.J. C (2004)',\n",
    "             xerr=log_binwidths/2, yerr=aleph_log_thrust_errs, **modplot.style('errorbar'))\n",
    "\n",
    "# RATIO PLOTS\n",
    "ax1.plot([np.min(ob['midbins_mc']), np.max(ob['midbins_mc'])], [1, 1], '--', color='blue', lw=0.75)\n",
    "genobs_hist, genobs_errs = modplot.calc_hist(ob['genobs'], bins=ob['bins_mc'], density=True)[:2]\n",
    "\n",
    "# central value calculations\n",
    "gen_hist_aleph_bins = modplot.calc_hist(ob['genobs'], bins=aleph_log_bins, density=False)[0]\n",
    "gen_hist_aleph_bins /= log_binwidths * np.sum(gen_hist_aleph_bins)\n",
    "aleph_ratio = aleph_log_thrust/(gen_hist_aleph_bins + 1e-50)\n",
    "ibu_ratio = ibu_hist/(genobs_hist + 10**-50)\n",
    "omnifold_ratio = omnifold_hist*corrs/(genobs_hist + 1e-50)\n",
    "\n",
    "# error calculations\n",
    "aleph_unc_ratio = aleph_log_thrust_errs/(gen_hist_aleph_bins + 10**-50)\n",
    "ibu_unc_ratio = ob['ibu_phi_unc']*corrs/(genobs_hist + 10**-50)\n",
    "omnifold_unc_ratio = omnifold_errs*corrs/(genobs_hist + 10**-50)\n",
    "\n",
    "# plot ALEPH ratio\n",
    "ax1.errorbar(aleph_log_midbins, aleph_ratio, xerr=log_binwidths/2, yerr=aleph_unc_ratio,\n",
    "             color='green', **modplot.style('errorbar', lw=1))\n",
    "\n",
    "# data ratio\n",
    "data_hist, data_errs = modplot.calc_hist(ob['dataobs'], bins=ob['bins_det'], density=True)[:2]\n",
    "ax1.errorbar(ob['midbins_det'], data_hist/(genobs_hist + 10**-50), xerr=ob['binwidth_det']/2,\n",
    "             yerr=data_errs/(genobs_hist + 10**-50), color='black', **modplot.style('errorbar'))\n",
    "\n",
    "# sim ratio\n",
    "sim_hist, sim_errs = modplot.calc_hist(ob['simobs'], bins=ob['bins_det'], density=True)[:2]\n",
    "ax1.errorbar(ob['midbins_det'], sim_hist/(genobs_hist + 10**-50), xerr=ob['binwidth_det']/2,\n",
    "             yerr=sim_errs/(genobs_hist + 10**-50), color='orange', **modplot.style('errorbar'))\n",
    "\n",
    "# plot IBU ratio\n",
    "ax1.errorbar(ob['midbins_mc'], ibu_ratio, xerr=ob['binwidth_mc']/2, yerr=ibu_unc_ratio,\n",
    "             color=ibu_style['color'], **modplot.style('errorbar'))\n",
    "\n",
    "# plot OmniFold ratio\n",
    "ax1.errorbar(ob['midbins_mc'], omnifold_ratio, xerr=ob['binwidth_mc']/2, yerr=omnifold_unc_ratio,\n",
    "             color='tab:red', **modplot.style('errorbar'))\n",
    "\n",
    "ax1.fill_between(ob['midbins_mc'], 1 - genobs_errs, 1 + genobs_errs, facecolor='blue', zorder=-2)\n",
    "\n",
    "loc, ncol = ob.get('legend_loc', 'upper right'), ob.get('legend_ncol', 2)\n",
    "order = [5, 1, 2, 0, 3, 4]\n",
    "modplot.legend(ax=ax0, frameon=False, loc=(0.4, 0.025), order=order, fontsize=8, markerscale=0)\n",
    "\n",
    "modplot.stamp(0.05, 0.9, ax=ax0, textops_update={'color': 'red', 'fontsize': 12},\n",
    "              line_0=r'\\textsc{Preliminary}')\n",
    "\n",
    "modplot.save(fig, 'LogThrustWithUniFold', tx=44, ty=252.75)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
